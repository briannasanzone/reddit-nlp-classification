{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b8c0c9b-2731-42f1-9f5d-8bb6855e28bf",
   "metadata": {},
   "source": [
    "#### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2120af67-4b2c-4e53-a8b1-c8a8eab3413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier, BaggingClassifier\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# skopt imports\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# distributions we'll need\n",
    "from scipy.stats import uniform, loguniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68930e03-e061-45ed-8845-c5c82a13ece4",
   "metadata": {},
   "source": [
    "#### **Read in .csv file & drop first column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20781ad-9df6-4749-a7f3-76afc6ee63be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RobusEtCeleritas</td>\n",
       "      <td>None of that means anything  You clearly have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1627142891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hydroxypcp</td>\n",
       "      <td>The legal limit varies among countries  It s c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1627140964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnthillOmbudsman</td>\n",
       "      <td>But magma chambers aren t hollow caverns   I m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1627140360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWormDude</td>\n",
       "      <td>According to this study  https   www research...</td>\n",
       "      <td>5</td>\n",
       "      <td>1627139388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trypanosoma_</td>\n",
       "      <td>Look up TH   cellular response  vs TH   humora...</td>\n",
       "      <td>-4</td>\n",
       "      <td>1627136260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                               body  score  \\\n",
       "0  RobusEtCeleritas  None of that means anything  You clearly have ...      3   \n",
       "1        hydroxypcp  The legal limit varies among countries  It s c...      0   \n",
       "2  AnthillOmbudsman  But magma chambers aren t hollow caverns   I m...      1   \n",
       "3         AWormDude   According to this study  https   www research...      5   \n",
       "4      Trypanosoma_  Look up TH   cellular response  vs TH   humora...     -4   \n",
       "\n",
       "   created_utc  subreddit  \n",
       "0   1627142891          1  \n",
       "1   1627140964          1  \n",
       "2   1627140360          1  \n",
       "3   1627139388          1  \n",
       "4   1627136260          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataframe saved as .csv file\n",
    "df = pd.read_csv('comments.csv')\n",
    "# drop first column\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f640c6-5a62-4225-bbb7-f31655e45ad3",
   "metadata": {},
   "source": [
    "#### **X, y, train_test_split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c005862d-de9c-4047-8cba-1dc2396d90ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['body']]\n",
    "y = df['subreddit']\n",
    "\n",
    "X = [word.lower().split() for word in df['body']]\n",
    "stops = set(stopwords.words('english'))\n",
    "posts_list = []\n",
    "for post in X:\n",
    "    meaningful_words = [word for word in post if word not in stops]\n",
    "    meaningful_post = \" \".join(meaningful_words)\n",
    "    posts_list.append(meaningful_post)\n",
    "    \n",
    "modeltext = pd.Series(posts_list)\n",
    "df['body'] = modeltext\n",
    "X = df['body']\n",
    "y = df['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                   y,\n",
    "                                   train_size=0.75,\n",
    "                                   stratify=y,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd707b2-5e78-478b-b84a-05b09d44a5bf",
   "metadata": {},
   "source": [
    "#### **Baseline Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d559b76-e656-4232-adc7-e91d3dc69e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.699791\n",
       "1    0.300209\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367d523-b8a0-4789-b0d5-6e43bf115303",
   "metadata": {},
   "source": [
    "#### **CountVectorizer SVC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8cada8-4316-4a5c-86ee-8081d9b24754",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_svc = Pipeline([\n",
    "    ('cv', CountVectorizer(stop_words='english')),\n",
    "    ('svc', SVC(random_state = 42))\n",
    "])\n",
    "\n",
    "params_svc = {\n",
    "#     'cv__max_features':[2_000, 5_000],\n",
    "#     'cv__min_df'        : [2, 3],\n",
    "#     'cv__max_df'        : [.90, .95],\n",
    "#     'cv__ngram_range'   : [(1,1)],\n",
    "    'svc__C': loguniform(1e-5,1e+2), \n",
    "    'svc__kernel': ['poly','rbf'],\n",
    "    'svc__gamma': ['scale','auto'],\n",
    "    'svc__degree': list(np.linspace(2,10,9)), \n",
    "    'svc__coef0': uniform(0,1), \n",
    "    'svc__shrinking': [True, False]   \n",
    "}\n",
    "\n",
    "rs_svc = RandomizedSearchCV(estimator = pipe_svc,\n",
    "                     param_distributions = params_svc,\n",
    "                     scoring = 'f1_weighted',\n",
    "                     n_iter = 2000,\n",
    "                     n_jobs = -2,\n",
    "                     cv = 5,\n",
    "                     verbose = 1)\n",
    "\n",
    "rs_svc.fit(X_train, y_train)\n",
    "print(rs_svc.best_params_)\n",
    "print(rs_svc.score(X_train, y_train))\n",
    "print(rs_svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e6e094-4c50-44df-9063-42889ca8b522",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rs_svc = rs_svc.predict(X_test)\n",
    "print(f'Best Score: {rs_svc.best_score_}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, preds_rs_svc)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a7754-8112-46f2-a8a9-503d16c00dd4",
   "metadata": {},
   "source": [
    "#### **TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f76549-2258-4455-92ad-1292d9580c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_tvsvc = Pipeline([\n",
    "    ('tv', TfidfVectorizer(stop_words='english')),\n",
    "    ('svc', SVC())\n",
    "]\n",
    ")\n",
    "params_tvsvc = {\n",
    "    'tv__max_features':[4000, 5000, 7000],\n",
    "    'tv__min_df'      : [2, 3],\n",
    "    'tv__max_df'      : [.85, .90],\n",
    "    'tv__ngram_range' : [(1,1)],\n",
    "    'svc__C': loguniform(1e-5,1e+2), \n",
    "    'svc__kernel': ['poly','rbf'],\n",
    "    'svc__gamma': ['scale','auto'],\n",
    "    'svc__degree': list(np.linspace(2,10,9)), \n",
    "    'svc__coef0': uniform(0,1), \n",
    "    'svc__shrinking': [True, False],   \n",
    "}\n",
    "\n",
    "rs_tvsvc = RandomizedSearchCV(estimator = pipe_tvsvc,\n",
    "                     param_distributions = params_tvsvc,\n",
    "                     scoring = 'f1_weighted',\n",
    "                     n_iter = 2000,\n",
    "                     n_jobs = -2,\n",
    "                     cv = 5,\n",
    "                     verbose = 1)\n",
    "\n",
    "rs_tvsvc.fit(X_train, y_train)\n",
    "print(rs_tvsvc.best_params_)\n",
    "print(rs_tvsvc.score(X_train, y_train))\n",
    "print(rs_tvsvc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b900d6-0728-4b56-8636-619fbfd408c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_rs_tvsvc = rs_tvsvc.predict(X_test)\n",
    "print(f'Best Score: {rs_tvsvc.best_score_}')\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, preds_rs_tvsvc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c03a5b-398e-4ef4-a14d-c29de828be1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
