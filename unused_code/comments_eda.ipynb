{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dc2820-81f5-4cef-8adf-f827c22ab01d",
   "metadata": {},
   "source": [
    "#### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3338f8ac-26d5-4294-850d-24725960232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import nltk\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2109456-698c-4f7a-98da-4e11ef8199af",
   "metadata": {},
   "source": [
    "#### **Read in dataframe saves as .csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f3a5d5f-6a93-48f5-9b0e-31caffae2f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RobusEtCeleritas</td>\n",
       "      <td>None of that means anything  You clearly have ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1627142891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hydroxypcp</td>\n",
       "      <td>The legal limit varies among countries  It s c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1627140964</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnthillOmbudsman</td>\n",
       "      <td>But magma chambers aren t hollow caverns   I m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1627140360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWormDude</td>\n",
       "      <td>According to this study  https   www research...</td>\n",
       "      <td>5</td>\n",
       "      <td>1627139388</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trypanosoma_</td>\n",
       "      <td>Look up TH   cellular response  vs TH   humora...</td>\n",
       "      <td>-4</td>\n",
       "      <td>1627136260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                               body  score  \\\n",
       "0  RobusEtCeleritas  None of that means anything  You clearly have ...      3   \n",
       "1        hydroxypcp  The legal limit varies among countries  It s c...      0   \n",
       "2  AnthillOmbudsman  But magma chambers aren t hollow caverns   I m...      1   \n",
       "3         AWormDude   According to this study  https   www research...      5   \n",
       "4      Trypanosoma_  Look up TH   cellular response  vs TH   humora...     -4   \n",
       "\n",
       "   created_utc  subreddit  \n",
       "0   1627142891          1  \n",
       "1   1627140964          1  \n",
       "2   1627140360          1  \n",
       "3   1627139388          1  \n",
       "4   1627136260          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in dataframe saved as .csv file\n",
    "df = pd.read_csv('comments.csv')\n",
    "# drop first column\n",
    "df.drop(columns='Unnamed: 0', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055573d6-8cdb-4730-933d-e3e25dbdcc6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14c8ade0-5c9f-4bc9-9579-db14b8b33eeb",
   "metadata": {},
   "source": [
    "##### **X,y train, test, split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571d68b-07c9-480a-8733-8287b8ba80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['body']]\n",
    "y = df['subreddit']\n",
    "\n",
    "X = [word.lower().split() for word in df['body']]\n",
    "stops = set(stopwords.words('english'))\n",
    "posts_list = []\n",
    "for post in X:\n",
    "    meaningful_words = [word for word in post if word not in stops]\n",
    "    meaningful_post = \" \".join(meaningful_words)\n",
    "    posts_list.append(meaningful_post)\n",
    "    \n",
    "modeltext = pd.Series(posts_list)\n",
    "df['body'] = modeltext\n",
    "X = df['body']\n",
    "y = df['subreddit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                   y,\n",
    "                                   train_size=0.75,\n",
    "                                   stratify=y,\n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecba415-cd27-4a4d-a65c-9259a3fd846a",
   "metadata": {},
   "source": [
    "##### **Baseline Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee9e701-05e5-4a43-b350-0c47e097d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c260ca-2d38-4207-80dc-8604deb57b1c",
   "metadata": {},
   "source": [
    "##### **Pipeline, CountVectorizer, Logistic Regression, Grid Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c29d2a-2e49-4706-9f3e-11e68fb63035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_cv = Pipeline([\n",
    "    ('cv', CountVectorizer(stop_words='english', max_features=10000)),\n",
    "    ('logreg', LogisticRegression())\n",
    "]\n",
    ")\n",
    "params_cv = {\n",
    "    'cv__max_features':[1_000, 4_000, 5_000],\n",
    "    'cv__min_df'      : [2, 3, 5],\n",
    "    'cv__max_df'      : [.90, .95],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "    'logreg__C'       : [.01, 1.0],\n",
    "    'logreg__penalty' : ['l1', 'l2'],\n",
    "    'logreg__solver'  : ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "gs_cv = GridSearchCV(pipe_cv, params_cv, cv=5, verbose=1, n_jobs = -1)\n",
    "gs_cv.fit(X_train, y_train)\n",
    "print(gs_cv.best_params_)\n",
    "print(gs_cv.score(X_train, y_train))\n",
    "print(gs_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6cf66-7f0b-4043-92d9-4a119d8d14c8",
   "metadata": {},
   "source": [
    "##### **Test Predictions and Accuracy Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f2a1c-ecb7-41cb-8ade-ecdf3cf320a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs_cv.predict(X_test)\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af136e76-e803-4bab-b3f3-f3122abe41c6",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a48cf9a-2e01-4f42-9b84-ae2dc4a51c1f",
   "metadata": {},
   "source": [
    "#### **TF-IDF Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5125eb2-c826-441d-96e2-89b2be72e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pipe_tv = Pipeline([\n",
    "    ('tv', TfidfVectorizer(stop_words='english')),\n",
    "    ('logreg', LogisticRegression())\n",
    "]\n",
    ")\n",
    "params_tv = {\n",
    "    'tv__max_features':[4000, 5000, 10000],\n",
    "    'tv__min_df'      : [1, 2, 5, 10],\n",
    "    'tv__max_df'      : [.95, .98],\n",
    "    'tv__ngram_range' : [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "gs_tv = GridSearchCV(pipe_tv, params_tv, cv=5, verbose=1, n_jobs = -1)\n",
    "gs_tv.fit(X_train, y_train)\n",
    "print(gs_tv.best_params_)\n",
    "print(gs_tv.score(X_train, y_train))\n",
    "print(gs_tv.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
